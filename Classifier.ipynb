{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as fn\n",
    "import os\n",
    "import random\n",
    "import math as m\n",
    "from PIL import Image\n",
    "\n",
    "from einops import rearrange, reduce, asnumpy, parse_shape\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Device is {device}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a183381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/how-to-add-noise-to-mnist-dataset-when-using-pytorch/59745\n",
    "\n",
    "dataset = tv.datasets.CIFAR100(root=\"./Datasets\", train=True, download=True, transform=tv.transforms.ToTensor())\n",
    "\n",
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = tv.datasets.CIFAR100(root=\"./Datasets\", train=True, transform=transform, download=True)\n",
    "dataset_verify = tv.datasets.CIFAR100(root=\"./Datasets\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "print(f\"Train set\\n {dataset}\")\n",
    "print(f\"Verify set\\n {dataset_verify}\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, drop_last=True, shuffle=True)\n",
    "dataloader_verify = torch.utils.data.DataLoader(dataset_verify, batch_size=256, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in dataloader:\n",
    "    print(len(images))\n",
    "    print(images[0].shape)\n",
    "    print(images[1].shape)\n",
    "    \n",
    "    print(images[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec032cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in dataloader:\n",
    "    for x in range(1, 13):\n",
    "        plt.subplot(2, 6, x)\n",
    "        plt.imshow(images[x].permute(1, 2, 0), cmap=plt.cm.binary)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af791f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_chan, bottleneck):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.bottleneck_in = nn.Conv2d(in_chan, bottleneck, kernel_size=1)\n",
    "        self.filter = nn.Conv2d(bottleneck, bottleneck, kernel_size=3, stride=1, padding=1, groups=bottleneck)\n",
    "        self.combination = nn.Conv2d(bottleneck, bottleneck, kernel_size=1, stride=1)\n",
    "        self.bottleneck_out = nn.Conv2d(bottleneck, in_chan, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(in_chan)\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            self.bottleneck_in,\n",
    "            nn.BatchNorm2d(bottleneck),\n",
    "            nn.ReLU(),\n",
    "            self.filter,\n",
    "            nn.BatchNorm2d(bottleneck),\n",
    "            nn.ReLU(),\n",
    "            self.combination,\n",
    "            nn.BatchNorm2d(bottleneck),\n",
    "            nn.ReLU(),\n",
    "            self.bottleneck_out,\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = out + self.layers(x)\n",
    "        return self.bn(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6388b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_example = ResidualBlock(384, 12)\n",
    "\n",
    "random_arr = torch.rand((1, 384, 16, 16))\n",
    "out = block_example(random_arr)\n",
    "\n",
    "print(f\"Parameter Number: {sum(p.numel() for p in block_example.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvExpand(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super(ConvExpand, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(nn.Conv2d(in_chan, out_chan, 1, 1),\n",
    "                                    nn.BatchNorm2d(out_chan),\n",
    "                                    nn.ReLU(inplace=False))\n",
    "\n",
    "    def forward(self, x):            \n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc79666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.entry = nn.Sequential(nn.Conv2d(3, 24, 5, 1, 2),\n",
    "                                   nn.BatchNorm2d(24),\n",
    "                                   nn.ReLU(),\n",
    "                                   ConvExpand(24, 48))\n",
    "\n",
    "        self.convolutions1 = nn.Sequential(ResidualBlock(48, 6),\n",
    "                                    ResidualBlock(48, 6),\n",
    "                                    ResidualBlock(48, 6),\n",
    "                                    ConvExpand(48, 96))\n",
    "        \n",
    "\n",
    "        self.convoltuions2 = nn.Sequential(ResidualBlock(96, 12),\n",
    "                                             ResidualBlock(96, 12),\n",
    "                                             ResidualBlock(96, 12),\n",
    "                                             ConvExpand(96, 196))\n",
    "        \n",
    "        self.convolutions3 = nn.Sequential(ResidualBlock(196, 24),\n",
    "                                             ResidualBlock(196, 24),\n",
    "                                             ResidualBlock(196, 41))\n",
    "        \n",
    "        self.decider = nn.Linear(196, 100)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.entry(x)\n",
    "        x = self.convolutions1(x)\n",
    "        x = fn.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.convoltuions2(x)\n",
    "        x = fn.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.convolutions3(x)\n",
    "        x = fn.avg_pool2d(x, 8)\n",
    "        \n",
    "        x = torch.flatten(x, 1, 3)\n",
    "\n",
    "        return self.decider(x)\n",
    "\n",
    "model = Discriminator()\n",
    "model = model.to(device)\n",
    "\n",
    "learning_decay = 0.98\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.00005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimiser, gamma=learning_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38007935",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in dataloader:\n",
    "    images = images.to(device)\n",
    "    output = model(images)\n",
    "    print(output.shape)\n",
    "    del output\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Parameter Number: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdcf731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(labels, output):\n",
    "    _, argmax = torch.max(output, dim=1)\n",
    "    training_accuracy = argmax.eq(labels).float().mean() * 100\n",
    "    return training_accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04465d8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "step_count = 0\n",
    "do_continue = True\n",
    "best_test_accuracy = 0.0\n",
    "\n",
    "print(\"Start\")\n",
    "\n",
    "while do_continue:\n",
    "    losses = []\n",
    "    training_accuracies = []\n",
    "    train_iter = iter(dataloader)\n",
    "    model.train()\n",
    "    for images, labels in train_iter:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = torch.nn.functional.cross_entropy(output, labels)\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        step_count += 1\n",
    "        \n",
    "        if step_count >= 15000:\n",
    "            do_continue = False \n",
    "            break\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        training_accuracies.append(get_accuracy(labels, output))\n",
    "    \n",
    "        if step_count % 100 == 0:\n",
    "            print(f\"{step_count} steps done!!!\")\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader_verify):\n",
    "            # sample x from the dataset\n",
    "            x, labels = batch\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "\n",
    "            output = model(x)\n",
    "            partial_loss = torch.nn.functional.cross_entropy(output, labels)\n",
    "            test_accuracy = get_accuracy(labels, output)\n",
    "\n",
    "            test_losses.append(partial_loss.item())\n",
    "            test_accuracies.append(test_accuracy)\n",
    "                \n",
    "    epoch += 1\n",
    "    average_train_accuracy = sum(training_accuracies)/len(training_accuracies)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "\n",
    "    if average_test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = average_test_accuracy\n",
    "        torch.save(model.state_dict(), \"best_basic_model\")\n",
    "\n",
    "    if epoch > 20:\n",
    "        scheduler.step()\n",
    "    print(f\"At epoch {epoch}:\")\n",
    "    print(f\"Train loss: {sum(losses)/len(losses)}, average train accuracy {average_train_accuracy}\")\n",
    "    print(f\"At testing loss: {sum(test_losses)/len(test_losses)} and test accuracy {average_test_accuracy}\")\n",
    "    print(f\"Num Steps: {step_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataloaders with image augmentation to regulirise the model\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, std=1.0):\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        return image + torch.randn(image.shape) * self.std\n",
    "    \n",
    "class ApplyImageAugmentation(object):\n",
    "    def __init__(self, probabilities=[0.7, 0.7]):\n",
    "        self.probabilities = probabilities\n",
    "        self.add_noise = AddGaussianNoise(0.015)\n",
    "        self.crop = tv.transforms.RandomResizedCrop((32, 32), scale=(0.70, 1.0), ratio=(0.8, 1.2))\n",
    "\n",
    "    def __call__(self, image):\n",
    "        do_crop = random.uniform(0, 1)\n",
    "        if do_crop < self.probabilities[0]:\n",
    "            image =  self.crop(image)\n",
    "        \n",
    "        do_apply_noise = random.uniform(0, 1)\n",
    "        if do_apply_noise < self.probabilities[1]:\n",
    "            image = self.add_noise(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    tv.transforms.RandomVerticalFlip(p=0.5),\n",
    "    tv.transforms.ColorJitter((0.8, 1.2), (0.8, 1.2), (0.8, 1.2), (-0.1, 0.1)),\n",
    "    tv.transforms.RandomResizedCrop((32, 32), scale=(0.70, 1.0), ratio=(0.8, 1.2)),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "batch_size=256\n",
    "\n",
    "dataset = tv.datasets.CIFAR100(root=\"./Datasets\", train=True, transform=transform, download=True)\n",
    "dataset_verify = tv.datasets.CIFAR100(root=\"./Datasets\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "dataloader_verify = torch.utils.data.DataLoader(dataset_verify, batch_size=batch_size, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af871adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final training loop to create the training graph\n",
    "from IPython import display as disp\n",
    "\n",
    "steps = 0\n",
    "\n",
    "test_loader = dataloader_verify\n",
    "do_continue = True\n",
    "plot_data = []\n",
    "epoch = 0\n",
    "max_test_accuracy = 0.0\n",
    "max_test_accuracy_std = 0.0\n",
    "attained_at_step = 0\n",
    "\n",
    "while do_continue:\n",
    "\n",
    "    # arrays for metrics\n",
    "    train_loss_arr = np.zeros(0)\n",
    "    train_acc_arr = np.zeros(0)\n",
    "    test_acc_arr = np.zeros(0)\n",
    "\n",
    "    train_iterator = iter(dataloader)\n",
    "    model.train()\n",
    "    # iterate through some of the train dateset\n",
    "    for i, (x, t) in enumerate(train_iterator):\n",
    "        x, t = x.to(device), t.to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        p = model(x)\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "        loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        steps += 1\n",
    "\n",
    "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
    "        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
    "\n",
    "        if steps >= 10000:\n",
    "            do_continue = False\n",
    "            break\n",
    "        \n",
    "    epoch += 1\n",
    "    if epoch > 20:\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    # iterate over the entire test dataset\n",
    "    for x,t in test_loader:\n",
    "        x,t = x.to(device), t.to(device)\n",
    "        p = model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
    "\n",
    "    mean_test_accuracy = test_acc_arr.mean()\n",
    "    if mean_test_accuracy > max_test_accuracy:\n",
    "        max_test_accuracy = mean_test_accuracy\n",
    "        max_test_accuracy_std = test_acc_arr.std()\n",
    "        attained_at_step = steps\n",
    "\n",
    "    # print loss and accuracy data\n",
    "    print('steps: {:.2f}, train loss: {:.3f}, train acc: {:.3f}±{:.3f}, test acc: {:.3f}±{:.3f}, max acc: {:.3f}±{:.3f} attained at {}'.format(\n",
    "        steps, train_loss_arr.mean(),train_acc_arr.mean(),train_acc_arr.std(),test_acc_arr.mean(),test_acc_arr.std(), max_test_accuracy, max_test_accuracy_std, attained_at_step))\n",
    "\n",
    "    # plot accuracy graph\n",
    "    plot_data.append([steps, np.array(train_acc_arr).mean(), np.array(train_acc_arr).std(), np.array(test_acc_arr).mean(), np.array(test_acc_arr).std()])\n",
    "    reward_list = []\n",
    "    plt.plot([x[0] for x in plot_data], [x[1] for x in plot_data], '-', color='tab:grey', label=\"Train accuracy\")\n",
    "    plt.fill_between([x[0] for x in plot_data], [x[1]-x[2] for x in plot_data], [x[1]+x[2] for x in plot_data], alpha=0.2, color='tab:grey')\n",
    "    plt.plot([x[0] for x in plot_data], [x[3] for x in plot_data], '-', color='tab:purple', label=\"Test accuracy\")\n",
    "    plt.fill_between([x[0] for x in plot_data], [x[3]-x[4] for x in plot_data], [x[3]+x[4] for x in plot_data], alpha=0.2, color='tab:purple')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    disp.clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
